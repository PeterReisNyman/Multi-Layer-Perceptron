{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1cfVlBGKDBW7"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "import  numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ds = sklearn.datasets.load_wine(return_X_y=False, as_frame=False)\n",
    "ix = [i for i,d in enumerate(ds['feature_names']) if d =='od280/od315_of_diluted_wines']\n",
    "ds['feature_names'][ix[0]] = 'ratio_of_diluted_wines'\n",
    "\n",
    "X = ds['data']\n",
    "Y = ds['target']\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"xtick.labelsize\": 6,\n",
    "    \"ytick.labelsize\": 6\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MGJMxQXGGyMo"
   },
   "outputs": [],
   "source": [
    "# 1 Base line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JDqqwrLkGyym"
   },
   "outputs": [],
   "source": [
    "# 1.1 Build an MLP classifier using the standard setup from SK-learn and evaluate its performance with regard to the performance\n",
    "# measures that we have used during the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UBuyAAZWDLfK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This model has 3 layers\n",
      "\n",
      "This model has (100,) neurons in its hiden layer\n",
      "\n",
      "[0.16666667 0.5        0.16666667 0.55555556 0.83333333 0.94444444\n",
      " 0.05555556 1.         1.         1.        ] \n",
      "\n",
      "0.6222222222222221 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        10\n",
      "           1       0.87      0.93      0.90        14\n",
      "           2       0.92      0.92      0.92        12\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.93      0.92      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split( X, Y, test_size = 0.2)\n",
    "model_default = MLPClassifier(max_iter = 10000)\n",
    "model_default.fit(x_tr, y_tr)\n",
    "print(f\"\\nThis model has {model_default.n_layers_} layers\\n\")\n",
    "print(f\"This model has {model_default.hidden_layer_sizes} neurons in its hiden layer\\n\")\n",
    "scores_default = cross_val_score(model_default, X, Y, cv = 10, scoring = 'accuracy')\n",
    "print(f\"{scores_default} \\n\")\n",
    "print(f\"{scores_default.mean()} \\n\")\n",
    "predictions_default = model_default.predict(x_te)\n",
    "\n",
    "print(classification_report(y_te, predictions_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M4cmYKr9G2hQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  0   1   2\n",
       "row_0           \n",
       "0      9   1   0\n",
       "1      0  13   1\n",
       "2      0   1  11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_te, predictions_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WQ2S4WYjG5g8"
   },
   "outputs": [],
   "source": [
    "# 1.2 Build an MLP classifier in accordance with the rules of thumb and your knowledge about the dataset (complexity, balance, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wIsXi6xGG9LV"
   },
   "outputs": [],
   "source": [
    "# 1.2.1 Motivate how you used the rules of thumb and your EDA knowledge to establish your MLP setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2Y5Je62Q6O0"
   },
   "source": [
    "We apply the rules of thumb by: 1. Determining number of input and output neurons: We have 13 input neurons, the 13 features of the wine and we have 3 output neurons, the three classes of the wine. So The hidden layer size should be between 3 and 13. 2. Calculate with the mean the input and output neurons and divide them by two. 3. The number of hidden neurons should be less than twice the size of the input layer. 4. The 2/3 the size of the input layer, plus the size of the output layer.\n",
    "\n",
    "1.   → 1-13 hidden neurons\n",
    "2.   (3 + 13) / 2 = 8 → 8 hidden neurons\n",
    "3.   23 < 2*13 → 1-25 hidden neurons\n",
    "4.   (3*(2/3))+13 → 15 hidden neurons\n",
    "\n",
    "Applying the rules of thumb gives us a result of 15 hidden neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zShnuttBG_Z4"
   },
   "outputs": [],
   "source": [
    "# 1.2.2 Build the model and evaluate it through the set of performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5MzLMv5XVqGH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 3 layers\n",
      "\n",
      "This model has 15 neurons\n",
      "\n",
      "[0.88888889 0.05555556 0.38888889 0.94444444 0.83333333 0.66666667\n",
      " 0.44444444 1.         0.58823529 0.17647059] \n",
      "\n",
      "0.5986928104575163 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.31      1.00      0.47        11\n",
      "\n",
      "    accuracy                           0.31        36\n",
      "   macro avg       0.10      0.33      0.16        36\n",
      "weighted avg       0.09      0.31      0.14        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emils\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\emils\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\emils\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split( X, Y, test_size = 0.2)\n",
    "model_HL = MLPClassifier(hidden_layer_sizes = (15), max_iter = 10000)\n",
    "model_HL.fit(x_tr, y_tr)\n",
    "print(f\"This model has {model_HL.n_layers_} layers\\n\")\n",
    "print(f\"This model has {model_HL.hidden_layer_sizes} neurons\\n\")\n",
    "scores_HL = cross_val_score(model_default, X, Y, cv = 10, scoring = 'accuracy')\n",
    "print(f\"{scores_HL} \\n\")\n",
    "print(f\"{scores_HL.mean()} \\n\")\n",
    "\n",
    "predictions_HL = model_HL.predict(x_te)\n",
    "\n",
    "print(classification_report(y_te, predictions_HL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KwSSlYkJWeFz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   2\n",
       "row_0    \n",
       "0      12\n",
       "1      13\n",
       "2      11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_te, predictions_HL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fyxu4_JfW9Ci"
   },
   "outputs": [],
   "source": [
    "# 3 Choose the best base line model out of the two above. Motivate why you deem this model setup to be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNKQ41vPWoPo"
   },
   "source": [
    "Our second model with our specified 15 neurons in the hidden layer achieves higher accuracy compared to the default model with 100 neurons in the hidden layer. We applied the rules of thumb, which we believe leads to it producing better accurac, we chose this model as the better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Try to find a model that outperforms the chosen base line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_pvdNJ0FWpYS"
   },
   "outputs": [],
   "source": [
    "#  2.1 You can use all the data preparation techniques that you have learned during the course. Motivate what steps you choose and why and the possible positive and negative consequences of those steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we start by oversampling the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, Y_ros = ros.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will standardize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_X = preprocessing.scale(X)\n",
    "standardized_X_ros = preprocessing.scale(X_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trO, x_teO, y_trO, y_teO = train_test_split(standardized_X_ros, Y_ros, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = MLPClassifier(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.1 Which model parameters would you like to include in your grid search (choose at least 3, you may use more) motivate your choices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.2 Identify the value range for each of the selected model parameter and motivate why these ranges are appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.3 Find the best combination of parameters using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs(h_param):\n",
    "    for t in range(5):    \n",
    "        model_final = MLPClassifier(max_iter=10000)\n",
    "        optimal_param = GridSearchCV(model_final, h_param)\n",
    "        optimal_param.fit(standardized_X_ros, Y_ros)\n",
    "        print(f'MODEL {t}: {optimal_param.best_params_} with score: {optimal_param.best_score_:.5f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 0: {'activation': 'tanh', 'hidden_layer_sizes': (71,), 'learning_rate': 'constant', 'learning_rate_init': 0.01} with score: 0.99070\n",
      "MODEL 1: {'activation': 'tanh', 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.1} with score: 0.99070\n",
      "MODEL 2: {'activation': 'tanh', 'hidden_layer_sizes': (43,), 'learning_rate': 'constant', 'learning_rate_init': 0.01} with score: 0.99070\n",
      "MODEL 3: {'activation': 'tanh', 'hidden_layer_sizes': (43,), 'learning_rate': 'constant', 'learning_rate_init': 0.01} with score: 0.99070\n",
      "MODEL 4: {'activation': 'tanh', 'hidden_layer_sizes': (43,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01} with score: 0.99070\n"
     ]
    }
   ],
   "source": [
    "\n",
    "H_param = {'hidden_layer_sizes': [(i,) for i in range(15,100,28)],\n",
    "           'activation': ['tanh', 'relu', 'identity', 'logistic'],\n",
    "           'learning_rate': ['constant', 'adaptive'],\n",
    "           'learning_rate_init': [10**-p for p in list(range(1,3))]}\n",
    "gs(H_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's tuning of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.01, 0.03, 0.05, 0.07, 0.09, 0.001, 0.003, 0.005, 0.007, 0.009000000000000001], 'learning_rate_init': [0.1, 0.30000000000000004, 0.5, 0.7000000000000001, 0.9, 0.01, 0.03, 0.05, 0.07, 0.09], 'activation': ['tanh'], 'hidden_layer_sizes': [(15,)], 'learning_rate': ['adaptive']}\n",
      "\n",
      "\n",
      "MODEL 0: {'activation': 'tanh', 'alpha': 0.03, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.03} with score: 0.99070\n",
      "MODEL 1: {'activation': 'tanh', 'alpha': 0.03, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.09} with score: 0.99535\n",
      "MODEL 2: {'activation': 'tanh', 'alpha': 0.03, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.05} with score: 0.99070\n",
      "MODEL 3: {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.05} with score: 0.99535\n",
      "MODEL 4: {'activation': 'tanh', 'alpha': 0.09, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.1} with score: 0.99535\n"
     ]
    }
   ],
   "source": [
    "H_param = {'alpha': [10**-p * m for p in range(2, 4) for m in range(1, 10, 2)],\n",
    "          'learning_rate_init': [10**-p * m for p in range(1, 3) for m in range(1, 10, 2)],\n",
    "          # good valeus \n",
    "          'activation':['tanh'], 'hidden_layer_sizes':[(15,)],'learning_rate':['adaptive']}\n",
    "print(H_param)\n",
    "print()\n",
    "print()\n",
    "gs(H_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.005, 0.0055000000000000005, 0.006, 0.006500000000000001, 0.007, 0.007500000000000001, 0.008, 0.0085], 'learning_rate_init': [0.05, 0.055, 0.06, 0.065, 0.07, 0.075, 0.08, 0.085], 'activation': ['tanh'], 'hidden_layer_sizes': [(15,)], 'learning_rate': ['adaptive']}\n",
      "\n",
      "\n",
      "MODEL 0: {'activation': 'tanh', 'alpha': 0.0055000000000000005, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.06} with score: 0.99070\n",
      "MODEL 1: {'activation': 'tanh', 'alpha': 0.005, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.055} with score: 0.99070\n",
      "MODEL 2: {'activation': 'tanh', 'alpha': 0.005, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.055} with score: 0.99535\n",
      "MODEL 3: {'activation': 'tanh', 'alpha': 0.005, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.075} with score: 0.99070\n",
      "MODEL 4: {'activation': 'tanh', 'alpha': 0.005, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.07} with score: 0.99070\n"
     ]
    }
   ],
   "source": [
    "H_param = {'alpha': [10**-4 * m for m in range(50, 90, 5)],\n",
    "          'learning_rate_init': [10**-3 * m for m in range(50, 90, 5)],\n",
    "          # good valeus \n",
    "          'activation':['tanh'], 'hidden_layer_sizes':[(15,)],'learning_rate':['adaptive']}\n",
    "\n",
    "print(H_param)\n",
    "print()\n",
    "print()\n",
    "gs(H_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.4 Evaluate the best set up of your MLP using cross validation and the performance measures that we discussed during the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9767441860465116\n"
     ]
    }
   ],
   "source": [
    "model_final = MLPClassifier(max_iter=10000, activation='tanh', hidden_layer_sizes=(15,), learning_rate='adaptive', alpha = 0.007, learning_rate_init = 0.07)\n",
    "model_final.fit(x_trO, y_trO)\n",
    "\n",
    "print(accuracy_score(y_teO, model_final.predict(x_teO)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95454545 0.95454545 1.         0.9047619  1.         1.\n",
      " 1.         1.         1.         1.        ] \n",
      "\n",
      "0.9813852813852814 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50        12\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.33        36\n",
      "   macro avg       0.11      0.33      0.17        36\n",
      "weighted avg       0.11      0.33      0.17        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emils\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\emils\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\emils\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "scores_final = cross_val_score(model_final, standardized_X_ros,Y_ros, cv = 10, scoring = 'accuracy')\n",
    "print(f\"{scores_final} \\n\")\n",
    "print(f\"{scores_final.mean()} \\n\")\n",
    "\n",
    "predictions_final = model_final.predict(x_te)\n",
    "\n",
    "print(classification_report(y_te, predictions_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.5 Compare the performance of your model with the base line model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27777778 0.94444444 0.94444444 0.44444444 0.83333333 1.\n",
      " 1.         1.         0.41176471 1.        ] \n",
      "\n",
      "0.7856209150326798 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores_default = cross_val_score(model_default, X,Y, cv = 10, scoring = 'accuracy')\n",
    "print(f\"{scores_default} \\n\")\n",
    "print(f\"{scores_default.mean()} \\n\")\n",
    "predictions_default = model_default.predict(x_te)\n",
    "\n",
    "print(classification_report(y_te, predictions_default))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
